#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\options conference
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-15
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 0
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
We consider the problem of finding connected components of a graph in presence
 of transient soft faults.
 Computing connected components, in particular when using the technique
 of label propagation, is a well-known and fundamental graph analysis primitive
 with many applications.
 We begin this study with a highly parallel label propagation (
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
sv
\end_layout

\end_inset

) algorithm for connected components, similar to the classical formulation
 of Shiloach and Vishkin
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "ShiloachVishkin"

\end_inset

.
 Label propagation refers to the iterative process of assigning candidate
 connected component labels to vertices until the labels of all the vertices
 in the same connected component converge to the same value.
 The challenge is that a transient soft fault occurring in some iteration
 can cause a mislabeling error; such an error can quickly 
\begin_inset Quotes eld
\end_inset

spread
\begin_inset Quotes erd
\end_inset

 in subsequent iterations, leading to additional incorrect labels or stalls
 of the convergence process.
 Thus, we seek efficient methods to detect and correct such errors.
\end_layout

\begin_layout Standard

\series bold
\emph on
\begin_inset Note Greyedout
status collapsed

\begin_layout Plain Layout

\series bold
\emph on
S
\series default
elf-correction para
\emph default
 
\end_layout

\begin_layout Itemize
Introduce self-correction LP (prior to this) 
\end_layout

\begin_layout Itemize
what is self-correction 
\end_layout

\begin_layout Itemize
define valid state and invalid state: 
\end_layout

\begin_layout Itemize
limitations of self-correction LP 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Prior to this, we presented a fault tolerant label propagation algorithm
 (sclp) based on ideas of self-correction in [cite].
 Both self-correcting and self-stabilzing algorithm share the notion of
 state, and distinguish between valid and invalid states.
 Briefly, a state of an algorithm is a subset of intermediate variables
 that allows to resume the algorithm.
 A state is called valid if an algorithm starting the state will converge
 to correct solution in fault free execution, otherwise invalid.
 In a fault free execution, an algorithm starts from a valid, remains in
 a valid state throughout the execution, and finally converge to a valid
 solution state.
 By contrast, in presence of hardware faults may bring the algorithm to
 a invalid state and eventually algorithm will fail.
 A self-correcting algorithm works by bringing the algorithm to a valid
 state by assuming it started from a previously known valid state.
\end_layout

\begin_layout Standard

\series bold
\emph on
\begin_inset Note Greyedout
status collapsed

\begin_layout Plain Layout

\series bold
\emph on
S
\series default
elf-stabilization para
\emph default
 
\end_layout

\begin_layout Itemize
Introduce self-stabilization: 
\end_layout

\begin_layout Itemize
advantage of SS over SC 
\end_layout

\begin_layout Itemize
SSLP as alternative to SCLP 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Self-stabilization was introduced by Dikstra in 1973 in context of distributed
 control.
 Briefly, an algorithm is self-stabilizing if starting from any arbitrary
 state, valid or invalid, algorithm comes to a valid state in finite number
 of steps.
 We previously showed potential of self-stabiling algorithm for constructing
 fault tolerant numerical iterative algorithms [cite].
 Self-stabilization is arguably more desirable property as it does not assume
 anything about history of execution.
 However, self-stabilized formulation of every algorithm may not exists.
\end_layout

\begin_layout Standard

\series bold
\emph on
\begin_inset Note Greyedout
status collapsed

\begin_layout Plain Layout

\series bold
\emph on
h
\series default
ow self-stab LP works
\emph default
 
\end_layout

\begin_layout Itemize
idea of correction step 
\end_layout

\begin_layout Itemize
difficulty in constructing a correcting step: vertex centric 
\end_layout

\begin_layout Itemize
correction step 
\end_layout

\begin_layout Itemize
advantage of correction step 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To construct a self-stabilizing label propagation algorithm, we first analyzed
 states of the label propagation algorithm and developed a set of sufficient
 conditions that ensures if the state is valid.
 We present an efficient correction step that verifies if the state is valid,
 and brings it to a valid state if the state is invalid.
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
Tell how is it different from self-correction method, (in contrast to to
 self-correcting)
\end_layout

\end_inset

 Since label propagation converges in very few iterations, we only run the
 correction step when the algorithm reports convergence.
 If algorithm is not in a valid state when it reports convergence then the
 correction step constructs a valid state and restart the computation from
 this valid state.
 Running label propagation from this valid state takes significantly fewer
 iteration to converge, which is significantly efficient to restarting the
 algorithm.
\end_layout

\begin_layout Standard

\series bold
\emph on
\begin_inset Note Greyedout
status collapsed

\begin_layout Plain Layout

\series bold
\emph on
s
\series default
ummary of results
\emph default
 
\end_layout

\begin_layout Itemize
what is overhead of correction step 
\end_layout

\begin_layout Itemize
overhead 
\end_layout

\begin_layout Itemize
comparison parameter 
\end_layout

\begin_layout Itemize
result 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Our self-stabilizing label propagation algorithm requires 
\begin_inset Formula $\mathcal{O}(V)$
\end_inset

 additional storage and correction step requires 
\begin_inset Formula $\mathcal{O}(Vlog(V)$
\end_inset

 computation, which is asymptotically a smaller fraction of cost of label
 propagation algorithm 
\begin_inset Formula $\mathcal{O}((V+E)log(V))$
\end_inset

.
 We tested fault tolerance properties of self-stabilizing label propagation
 algorithm a number of representative test problems.
 Self-stabilizing label propagation algorithm is significantly more efficeint
 than existing fault tolerance techniques such as triple modular redundency
 (TMR).
 In particular, Self-stabilizing label propagation algorithm takes only
 20% additional iteration even in presence of 
\begin_inset Formula $2^{-9}$
\end_inset

 bit flips per memory iteration.
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% To derive a method, we introduce a principle that we call 
\backslash
emph{self-correction}.
 In this approach, one first considers the possible states of the algorithm
 and divides them into 
\backslash
emph{valid} and 
\backslash
emph{invalid} states.
 A valid state is one from which the algorithm will converge to a correct
 result assuming a fault-free execution.
 By contrast, from an invalid state the algorithm instead produces an incorrect
 result or diverges.
 Now suppose that at some point in its execution the algorithm is in a valid
 state, but after which point a fault occurs, bringing the algorithm into
 an invalid state.
 A 
\backslash
emph{self-correcting algorithm} detects that it is in an invalid state,
 and using the previously known valid state, brings itself back to 
\backslash
emph{some} valid state.
 Importantly, this new valid state need 
\backslash
emph{not} be identical to the previously valid state.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% This notion of self-correcting behavior differs from other forms of resilient
 behavior.
 For instance, a checkpoint-restart scheme would, upon detecting an invalid
 state, restore the 
\backslash
emph{same} previously valid state; by contrast, a self-correcting algorithm
 moves only to 
\backslash
emph{some} valid state.
 This difference makes self-correction a more general principle.
 However, it is unclear 
\backslash
emph{a priori} whether a self-correcting algorithm will be faster or slower
 than checkpoint-restart.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% Self-correction also differs from 
\backslash
emph{self-stabilization}, which is a design principle for resilient algorithms
 that we considered in our prior work for certain iterative numerical solvers~
\backslash
cite{sao2013sscg}.
 A self-stabilizing algorithm can restore itself to a valid state starting
 in an 
\backslash
emph{arbitrary} state, whether valid or invalid; by contrast, self-correction
 requires a previously known valid state.
 Thus, self-stabilization is a stronger notion than self-correction.
 However, this difference, combined with the explicit use of a previously
 known state, also suggests that a self-correcting algorithm can be more
 efficient than a self-stabilizing algorithm for the same computational
 problem.
 That's because a self-correcting algorithm has more information in the
 form of the previously known valid state.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% This paper applies self-correction to the label propagation-based connected
 components problem, thereby yielding a self-correcting algorithm that we
 call 
\backslash
emph{Fault-Tolerant 
\backslash
sv{}}, or 
\backslash
ftsv.
 This algorithm requires an augmented data structure and the ability to
 run detection and correction schemes in a selective reliability mode.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% Despite these restrictions and overheads, the condition we identify to
 distinguish invalid states leads to an efficient implementation.
 Theoretically, the baseline (fault-
\backslash
emph{in}tolerant) 
\backslash
sv{} algorithm has a complexity of $
\backslash
mathcal{O}(|E|+|V|)$ per iteration, where $|E|$ is the number of edges and
 $|V|$ is the number of vertices in the graph $G=(V,E)$.
 
\backslash
ftsv{}, the new fault-tolerant algorithm, adds a modest $
\backslash
mathcal{O}(|V|)$ storage and has the same bounds as the original.
 We also evaluate 
\backslash
ftsv{} empirically on realistic input graphs.
 We observe 10-35
\backslash
% increases in execution time over the fault-intolerant 
\backslash
sv{}.
 This increase includes cases of extremely high fault rates, such as a single
 error for every 64-1024 memory operations.
 At such rates, a system would be considered unusually unreliable.
 In any case, we observe that computational overheads increase gracefully
 as fault rates increase without a decrease in the convergence rate.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%ODED - I just added a comment on the fact that the new algorithm converges
 as fast as the fault-intolerant algorithm.
 
\end_layout

\end_inset


\end_layout

\end_body
\end_document
